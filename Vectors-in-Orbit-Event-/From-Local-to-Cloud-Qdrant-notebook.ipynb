{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huGOEDKrAxvy"
   },
   "source": [
    "#### Creating a collection/table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zi7vun5yAb_h"
   },
   "outputs": [],
   "source": [
    "PUT /collections/rentals\n",
    "{\n",
    "  \"vectors\": {\n",
    "    \"size\": 300,\n",
    "    \"distance\": \"Cosine\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUekrSDgA7fK"
   },
   "source": [
    "#### Insert/Write:\n",
    "- This request demonstrates a batch operation to upload data points into a collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AkqOrLH-Agt5"
   },
   "outputs": [],
   "source": [
    "PUT /collections/rentals/points\n",
    "{\n",
    "  \"batch\": {\n",
    "    \"ids\": [1, 2],\n",
    "    \"vectors\": [\n",
    "      [0.9, -0.5, ..., 0.0],\n",
    "      [0.1, 0.4, ..., 0.3],\n",
    "    ],\n",
    "    \"payload\": [\n",
    "      {\"city\": \"Bangalore\", \"sqft\": 990, \"img_url\": \"example.com/rental1.jpg\", \"tags\": [\"...\"]},\n",
    "      {\"city\": \"Hyderabad\", \"sqft\": 1550, \"img_url\": \"example.com/rental2.jpg\", \"description\": \"...\"}\n",
    "    ]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DviFDHKQBOHS"
   },
   "source": [
    "#### Field indexing:\n",
    "- This section explains how to create indices on payload fields to improve filtering efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2yo8RUDYAgrI"
   },
   "outputs": [],
   "source": [
    "// Vector indexing happens by default\n",
    "// Each payload index adds more links to keep the graph connected for effective filtering\n",
    "// Repeat for 'sqft' field with 'integer' type\n",
    "PUT /collections/rentals/index\n",
    "{\n",
    "  \"field_name\": \"city\",\n",
    "  \"field_schema\": {\n",
    "    \"type\": \"keyword\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9ItZhPHBeBf"
   },
   "source": [
    "#### Search/Read:\n",
    "- This demonstrates a vector search query combined with specific metadata filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3AujJDuAgob"
   },
   "outputs": [],
   "source": [
    "POST /collections/rentals/points/search\n",
    "{\n",
    "  \"query\": [0.2, 0.3, ..., 0.4], // generated from user query (text using same model\n",
    "  \"filter\": { \"must\": [ {\"key\": \"city\", \"match\": {\"value\": \"Bangalore\"}}, {\"key\": \"sqft\", \"range\": { \"gte\": 1000 }}]},\n",
    "  \"limit\": 10\n",
    "}\n",
    "\n",
    "// Response:\n",
    "[\n",
    "  {\"id\": 4, \"score\": 0.56, \"payload\": {...}},\n",
    "  {\"id\": 2, \"score\": 0.40, \"payload\": {...}},\n",
    "  {\"id\": 5, \"score\": 0.23, \"payload\": {...}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tiei5ja4Eohh"
   },
   "outputs": [],
   "source": [
    "# Install the Qdrant client if it's not already installed\n",
    "!uv pip install qdrant-client -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aWzVhjuIpxxu"
   },
   "source": [
    "#### Setup Qdrant Cloud Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zi4IiRKFPMsK",
    "outputId": "21a164c8-7fd6-435d-cdd5-e53e26247bd6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Qdrant Cloud and collection created!\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "\n",
    "# Qdrant Cloud URL and API Key\n",
    "from google.colab import userdata\n",
    "QDRANT_URL = userdata.get('QDRANT_URL')\n",
    "QDRANT_API_KEY = userdata.get('QDRANT_API_KEY')\n",
    "\n",
    "cloud_client = QdrantClient(\n",
    "    url=QDRANT_URL,\n",
    "    api_key=QDRANT_API_KEY,\n",
    ")\n",
    "\n",
    "cloud_client.create_collection(\n",
    "    collection_name=\"testtest\",\n",
    "    vectors_config=VectorParams(size=4, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "print(\"Connected to Qdrant Cloud and collection created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLAB7GQrp03W"
   },
   "source": [
    "#### Setup In-Memory Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44-lCMD_AgjJ",
    "outputId": "322f4281-c042-4c3a-820f-4509adb02d29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In-memory collection created successfully!\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "# Initialize client in memory\n",
    "memory_client = QdrantClient(\":memory:\")\n",
    "\n",
    "# Create a collection\n",
    "memory_client.create_collection(\n",
    "    collection_name=\"test_collection\",\n",
    "    vectors_config=VectorParams(size=4, distance=Distance.DOT),\n",
    ")\n",
    "\n",
    "print(\"In-memory collection created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHdpVaFzp3Du"
   },
   "source": [
    "#### Setup Local Storage Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o6w9-nWlAggp",
    "outputId": "c52cfbe6-439b-4fc8-d301-35db20e80f8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local persistent collection created in './qdrant_storage'\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "# Initialize client and point to a local directory\n",
    "# This will create a folder named 'qdrant_storage' in your Colab files\n",
    "local_client = QdrantClient(path=\"./qdrant_storage\")\n",
    "\n",
    "local_client.create_collection(\n",
    "    collection_name=\"local_collection\",\n",
    "    vectors_config=VectorParams(size=4, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "print(\"Local persistent collection created in './qdrant_storage'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wMFWPHnp6de"
   },
   "source": [
    "#### Insert Raw Vectors (Manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rMH-2begAgeA",
    "outputId": "f282f066-9a88-4de3-a532-95a0b42339ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points inserted successfully!\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.models import PointStruct\n",
    "\n",
    "# 1. Prepare your data (Points)\n",
    "# Each point needs: an ID, a Vector (list of floats), and optional Payload (metadata)\n",
    "points = [\n",
    "    PointStruct(\n",
    "        id=1,\n",
    "        vector=[0.05, 0.61, 0.76, 0.74],\n",
    "        payload={\"city\": \"Tunis\", \"event\": \"Hackathon\"}\n",
    "    ),\n",
    "    PointStruct(\n",
    "        id=2,\n",
    "        vector=[0.19, 0.81, 0.75, 0.11],\n",
    "        payload={\"city\": \"London\", \"event\": \"Workshop\"}\n",
    "    ),\n",
    "    PointStruct(\n",
    "        id=3,\n",
    "        vector=[0.36, 0.55, 0.47, 0.94],\n",
    "        payload={\"city\": \"Tunis\", \"event\": \"Demo\"}\n",
    "    ),\n",
    "]\n",
    "\n",
    "# 2. Perform the Upsert\n",
    "# This works the same for your 'client', 'client_in_memory', or 'client_local'\n",
    "cloud_client.upsert(\n",
    "    collection_name=\"testtest\",\n",
    "    points=points\n",
    ")\n",
    "\n",
    "print(\"Points inserted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0C7IT9pQQRp"
   },
   "source": [
    "#### For Qdrant Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Se-UOZUqAgbS"
   },
   "outputs": [],
   "source": [
    "cloud_client.upsert(\n",
    "    collection_name=\"cloud_collection\",\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FZs7iJSJQN85"
   },
   "source": [
    "#### For In-Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_N5PRc8QFx4"
   },
   "outputs": [],
   "source": [
    "memory_client.upsert(\n",
    "    collection_name=\"memory_collection\",\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6Nl7FpdQLRR"
   },
   "source": [
    "#### For Local Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l_lsdPvYQFtR"
   },
   "outputs": [],
   "source": [
    "local_client.upsert(\n",
    "    collection_name=\"local_collection\",\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p7IMqAoEUnV4"
   },
   "outputs": [],
   "source": [
    "!uv pip install -q sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHZ34UXWp-Pf"
   },
   "source": [
    "#### Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "a10cf5b7a4e8432cba9a4c1c471393d7",
      "737c9cb7b06940fe91bd9a1223fae9a1",
      "1fca9612d5ab44a6b8401346c95816ce",
      "7ca27a254c76421e998f85fc148cb640",
      "0fb62c843439424196539b149d2cda58",
      "0d599fc107504df9a5c0cc051e467591",
      "45e5ba9e97fd445c812af814077e9187",
      "4bd1eef122fd406daf552e48c774c1ae",
      "a018d1e379c24e8d9b33b7c920cbd6fd",
      "7a51c4f2e892467ea4f9147695eb885c",
      "0bafa1dae1c147a0b4f720cd9f2f284c",
      "cc7aa9de1d0746eba552cdf8177cabb8",
      "5aa6cb78a4a844e2b3e9db0cc0d330d7",
      "e50a7ee5cc8d4ff8bba29c0f3064977e",
      "4b25508b5dc2452bb0ef2883a637b8a6",
      "e9b079254470431ca1aace6c3cf5eb6a",
      "0b727a3da18f4c13994d0b29aebc0e9a",
      "72994e2d573b40f196b61960a596c373",
      "e5e6624d689f430fb5c59ac42b3fe70c",
      "fad3653370e64be894f77f9cbb9a9fd2",
      "e0e4f765563b490386356c788dff62e7",
      "284efa8a6efc43f8a87d99312f2a4157",
      "1f2d3cfb516a43488ab4c13f7974d73d",
      "93404f5ed4a54c18a572b8c780fd0f33",
      "81adb514ced74bb6a6e9b081cb5b19cd",
      "df5853f972ee43578cd18bbbcbec0e0d",
      "4d180cd86b654c90acc51d4b33189786",
      "5c235746be1545c89dfe1043e738c9f9",
      "44b6964282c14f87b21ee15f379e4b20",
      "948d8af6d19b406ab8e466eb0820a502",
      "166a502b697a442aa667698c624298d5",
      "3cdc494b11774e8cb145943418018853",
      "506e5d5394bd469d8036d13c8043f2e0",
      "7addc00762a54e8c844580a87473fba2",
      "4801fdb87100405da0bc197ae0f57483",
      "bb6f046665d340e382d047ed1dc10416",
      "073643f0dc544d889fdc2884a19a619c",
      "aadb8412b1e04819bacef45f83d439b0",
      "0f36bd1582a740ec9fa3b99dc3ae93d9",
      "8ea833ea66254a6e88905f79b2677a3a",
      "1e4324a385784ac1bfd683493e3e91e3",
      "a3b2e6a627f4422092b77ef6d054e856",
      "03815a75f566471fa593b030235fb2d8",
      "0220b4009b4440938e180a8ddda92fe7",
      "173d0d65b3cb4707b16a5d21e648ffbd",
      "b1e3321e35ae4849b2e48f9f6cfc5d58",
      "8b5319ebdc744345a372bb5132e087e0",
      "93dc36e36a9545b1a89f06a4ded13b98",
      "0a737b4140464ca7a8240112e92ec24a",
      "77111b4578e4448fbaa763d6ade16678",
      "d5811965e1da4b3ca3962166ca864441",
      "9f448c0f7e2b498ab9f5dbba5b556705",
      "08c25f20b97045e695778746a0373b37",
      "f48d6a24e1cf4ef2a54aec1508840800",
      "bd97d62c03994c8487a3e22c4e7b7947",
      "284841e85216403db5be8b3817a7cc5b",
      "4a48b23a1dd8454bb5a2fc78a14c4e64",
      "053b9b0212be4d4ea44154e5658e6b52",
      "de00de2b55d041a2afb04f7ad2f38f0d",
      "07166866dc2f4e1eb14bef0311fe72a4",
      "4d58d137751a42a99982abdc677b2c0b",
      "5b2a1c19c6504cff8b4c62f1ef4fdee8",
      "b277da571a3e4f1cbf4ab241eb2ab2bd",
      "22051de05d4740f5917022dedb9820f6",
      "3441243bac094b56ad6998142581ecbf",
      "edf491642fd34d00a023c96a0667af61",
      "c0584079bd8043b69c1c1e68d4cce75d",
      "ce2e6dc5b04e4ecdac0cf7d5bc878e47",
      "198b992531a54c2faf22cdd49a3f79c5",
      "9682f6b8e47841a1a9888e1cfbf4b8fb",
      "16506c2111234e528f7ab1c58de0031e",
      "7527a0be51994a8fa7761e2d6f33cc67",
      "6b22bfab3f0f471b8a45bbb924c469c1",
      "e7c41591e49e4245acaa0e1bea56c34d",
      "f789cd3f7f3a4a0fba2abb73127c64cf",
      "1f75fbf0e25b4d34b67dbc844e22744e",
      "3e49a6f636064ae496f304b8978ae706",
      "ec7c622e9da640df9634eae406a1bfbc",
      "41a568dbc53541adb610d8917c07cd07",
      "5a8c76805e034b46b6b1d3d2ae4fda78",
      "6ca308080b644d93ada7844a7e3c7b75",
      "06e71342026244a38365cb707348f233",
      "888122e4440a4f9587c9989c47fcc579",
      "c32b58b88a0f4976aae9ad373c719e7f",
      "6c1cb07a94584a88a210876271231ca7",
      "650da155bbd144548358ff50ee45a18a",
      "158fcbefeaf748ce922035a59b339e1f",
      "fa33e2f48c2d443e86e1d2513e858219",
      "93c6e909de5f4769a2e4ab2832d512e9",
      "4cf04da61821480b832ef8df5054d2b4",
      "a0d969e6a28d475780969188d7335cbb",
      "922bdc34dad54696a2ac11f34bd81283",
      "cda0ff830dcf443a9cbfc1321c274eeb",
      "bf1041c10aeb4caea268cf00f365928f",
      "efb64139ab6548048d7c7a8d5e56e980",
      "c1303a3056d648f5b41a2cb7ff2fc4ad",
      "1c1d64564be4454282fd077984b8732d",
      "45042220227c4428a4a25e39b33aef71",
      "f7ab98502afc4fffb6ae0795b253ddbd",
      "73b98c19aab74257870b89c1459157c1",
      "3de12784712041e589e89f4fee0456f8",
      "1321519fca02495a95bddde4e145eb95",
      "7ae23b2a10cf451aaba13d642924122c",
      "e9c90d74221f4618967c5051852644aa",
      "8e71ca0e13f9428898a20b268ca72172",
      "6da50ceeb12b4b04974b9ad565cda317",
      "2abb7730299240bcb2618835756b1e84",
      "743460f839f940f1881e4fccdc5696c1",
      "4bb3744dfc9a4e4db972476f16146246",
      "32ef9305ab7f42d3a8cdab612664b311",
      "e136f8cb42c64845b8a4019a17bb0da6",
      "adf32c2b2429487090f8b25a07259b6f",
      "67be5ef95aed464aa180b1c98d291a05",
      "66c780efee5c43e1ab019528f7bda95d",
      "540ce6f4176a47d58fe4d1f543b2f17e",
      "ca44650485574bec90cede399d3cde80",
      "a4aea1cf88244fdc9f5af2ac49ba8cca",
      "2133739780724a27a1dbc8f6bcdb8c54",
      "3b3669be3b4b4cf081f9be744f30fa56",
      "195cd9e60a4e4940aafeebe13dca557c",
      "c6847e4cbfa04a4e8527fe1b8b29995a"
     ]
    },
    "id": "UcTselNdQFqh",
    "outputId": "87a8601a-f9d4-4bfb-ad7e-242c9e0f0eea"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10cf5b7a4e8432cba9a4c1c471393d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7aa9de1d0746eba552cdf8177cabb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2d3cfb516a43488ab4c13f7974d73d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7addc00762a54e8c844580a87473fba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173d0d65b3cb4707b16a5d21e648ffbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284841e85216403db5be8b3817a7cc5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0584079bd8043b69c1c1e68d4cce75d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7c622e9da640df9634eae406a1bfbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c6e909de5f4769a2e4ab2832d512e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b98c19aab74257870b89c1459157c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e136f8cb42c64845b8a4019a17bb0da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Initialize the model (This will download it the first time)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Note: This model produces vectors of size 384.\n",
    "# You MUST ensure your collection size matches this (384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TVDLbRi1dxO-",
    "outputId": "b62886fb-6181-4b35-c091-d2627bc946f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding size equal to: 384\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_SIZE= len(model.encode(\"Hello World\"))\n",
    "print(f\"embedding size equal to: {EMBEDDING_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0nD1sjeCfKKj"
   },
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"demo_day01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ewVkrnKJU13Q",
    "outputId": "a8d508e7-dd8a-48cc-81e9-15974c139e49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Qdrant Cloud and collection created!\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "# Qdrant Cloud URL and API Key\n",
    "from google.colab import userdata\n",
    "QDRANT_URL = userdata.get('QDRANT_URL')\n",
    "QDRANT_API_KEY = userdata.get('QDRANT_API_KEY')\n",
    "\n",
    "cloud_client = QdrantClient(\n",
    "    url=QDRANT_URL,\n",
    "    api_key=QDRANT_API_KEY,\n",
    ")\n",
    "\n",
    "cloud_client.create_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    vectors_config=VectorParams(size=EMBEDDING_SIZE, distance=Distance.COSINE),\n",
    ")\n",
    "\n",
    "print(\"Connected to Qdrant Cloud and collection created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjp9ooh0UmOa",
    "outputId": "969723ea-3999-4ab5-a36a-504e185163a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully inserted 11 text-based points.\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.models import PointStruct\n",
    "\n",
    "# Sample text data\n",
    "documents = [\n",
    "    {\"id\": 1, \"text\": \"we have some participants from sousse.\", \"city\": \"Sousse\"},\n",
    "    {\"id\": 2, \"text\": \"we have some participants from sfax.\", \"city\": \"Sfax\"},\n",
    "    {\"id\": 3, \"text\": \"hafedh talked about chonkie and qdrant.\", \"talk\": \"chonkie\"},\n",
    "    {\"id\": 4, \"text\": \"eya talked about ADK and Qdrant MCP\", \"talk\": \"ADK\"},\n",
    "    {\"id\": 5, \"text\": \"arbi talked about Qdrant.\", \"talk\": \"Qdrant\"},\n",
    "    {\"id\": 6, \"text\": \"Qdrant event is huge.\", \"city\": \"Tunis\"},\n",
    "    {\"id\": 7, \"text\": \"there is nothing we can do.\", \"person\": \"Napoleon\"},\n",
    "    {\"id\": 8, \"text\": \"this talk is on discord.\", \"media\": \"discord\"},\n",
    "    {\"id\": 9, \"text\": \"the media posts are on facebook.\", \"media\": \"facebook\"},\n",
    "    {\"id\": 10, \"text\": \"Qdrant is a vector database.\", \"city\": \"Berlin\"},\n",
    "    {\"id\": 11, \"text\": \"The hackathon is in Tunis.\", \"city\": \"Tunis\"},\n",
    "]\n",
    "\n",
    "# Prepare points\n",
    "points = []\n",
    "for doc in documents:\n",
    "    # Convert text to a list of floats (the embedding)\n",
    "    vector = model.encode(doc[\"text\"]).tolist()\n",
    "\n",
    "    # Dynamically build payload to avoid KeyError\n",
    "    payload_content = {\"text\": doc[\"text\"]}\n",
    "    if \"city\" in doc:\n",
    "        payload_content[\"city\"] = doc[\"city\"]\n",
    "    if \"talk\" in doc:\n",
    "        payload_content[\"talk\"] = doc[\"talk\"]\n",
    "\n",
    "    points.append(\n",
    "        PointStruct(\n",
    "            id=doc[\"id\"],\n",
    "            vector=vector,\n",
    "            payload=payload_content\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Insert into Cloud\n",
    "cloud_client.upsert(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    points=points\n",
    ")\n",
    "\n",
    "print(f\"Successfully inserted {len(points)} text-based points.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdVpG1TzqCj-"
   },
   "source": [
    "#### Delete Points by ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9txIucr3UmLx",
    "outputId": "e426904b-3bf3-422e-d592-022a7801d4f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points 11 , 10 , 9 deleted.\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.models import PointIdsList\n",
    "\n",
    "cloud_client.delete(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    points_selector=PointIdsList(\n",
    "        points=[11, 10 , 9 ],  # List of IDs you want to remove\n",
    "    ),\n",
    ")\n",
    "print(\"Points 11 , 10 , 9 deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZyXTS5fqEyH"
   },
   "source": [
    "#### Delete Points by Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t9c0OBiPUmJJ",
    "outputId": "8d4d609e-65ca-47c6-dd01-c2f62f91c7ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All pts about ADK deleted.\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.models import Filter, FieldCondition, MatchValue, PayloadSchemaType\n",
    "\n",
    "# Create a payload index for the 'city' field\n",
    "cloud_client.create_payload_index(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    field_name=\"talk\",\n",
    "    field_schema=PayloadSchemaType.KEYWORD\n",
    ")\n",
    "\n",
    "cloud_client.delete(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    points_selector=Filter(\n",
    "        must=[\n",
    "            FieldCondition(key=\"talk\", match=MatchValue(value=\"ADK\")),\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "print(\"All pts about ADK deleted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8QZ7e6dhqG3H"
   },
   "source": [
    "#### Filter Search (Match Any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V3W4MJQRUmGg",
    "outputId": "b6d246ee-b5df-40ae-9f91-1b120bba6f50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Record(id=3, payload={'text': 'hafedh talked about chonkie and qdrant.', 'talk': 'chonkie'}, vector=None, shard_key=None, order_value=None)],\n",
       " None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qdrant_client.models import Filter, FieldCondition, MatchAny\n",
    "\n",
    "results = cloud_client.scroll(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    scroll_filter=Filter(\n",
    "        must=[\n",
    "            FieldCondition(\n",
    "                key=\"talk\",\n",
    "                match=MatchAny(any=[\"chonkie\", \"ADK\"])\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRXfGBdHk8xH"
   },
   "source": [
    "#### Retrieve All \"Talk\" Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OddJMuPeUmBI",
    "outputId": "2ae1e14a-6c5c-4326-9443-c7d08c222c5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total talks found: 2\n",
      "- chonkie: hafedh talked about chonkie and qdrant.\n",
      "- Qdrant: arbi talked about Qdrant.\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client.models import Filter, IsEmptyCondition, PayloadField\n",
    "\n",
    "# This finds IDs 3, 4, and 5 (everything with a \"talk\" key)\n",
    "points, _ = cloud_client.scroll(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    scroll_filter=Filter(\n",
    "        must_not=[\n",
    "            IsEmptyCondition(\n",
    "                is_empty=PayloadField(key=\"talk\")\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "print(f\"Total talks found: {len(points)}\")\n",
    "for p in points:\n",
    "    print(f\"- {p.payload['talk']}: {p.payload['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-w_79WGlSrw"
   },
   "outputs": [],
   "source": [
    "!uv pip install -q \"chonkie[qdrant]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4kbaofrsLqn"
   },
   "source": [
    "#### sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mzEFat7LlSpI",
    "outputId": "c962d424-67b3-4137-f4ca-3993a9af656a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text file 'hackathon_info.txt' created.\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"\"\"\n",
    "Qdrant is a high-performance vector database designed for advanced AI applications.\n",
    "It allows users to store and search large collections of high-dimensional vectors.\n",
    "Vector databases are essential for Retrieval-Augmented Generation (RAG).\n",
    "Hafedh is hosting a hackathon in Tunis today to teach people about Qdrant.\n",
    "Participants are learning about different storage modes like Cloud, Memory, and Local.\n",
    "Chunking is the process of breaking large text into smaller pieces for better retrieval.\n",
    "Chonkie is a lightweight and fast library for chunking text in Python.\n",
    "Using the right chunking strategy improves the accuracy of semantic search.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SbeO2Z7klb4O"
   },
   "outputs": [],
   "source": [
    "from chonkie import QdrantHandshake, TokenChunker\n",
    "from google.colab import userdata\n",
    "\n",
    "# Common Embedding Model for all handshakes\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "# 1. CLOUD HANDSHAKE\n",
    "cloud_handshake = QdrantHandshake(\n",
    "    url=userdata.get('QDRANT_URL'),\n",
    "    api_key=userdata.get('QDRANT_API_KEY'),\n",
    "    collection_name=\"cloud_handshake_demo\",\n",
    "    embedding_model=MODEL_NAME\n",
    ")\n",
    "\n",
    "# # 2. IN-MEMORY HANDSHAKE\n",
    "# # Use :memory: for ephemeral sessions\n",
    "# memory_handshake = QdrantHandshake(\n",
    "#     location=\":memory:\",\n",
    "#     collection_name=\"memory_demo\",\n",
    "#     embedding_model=MODEL_NAME\n",
    "# )\n",
    "\n",
    "# # 3. LOCAL PATH HANDSHAKE\n",
    "# # Persistent folder in your Colab files\n",
    "# local_handshake = QdrantHandshake(\n",
    "#     path=\"./qdrant_handshake_storage\",\n",
    "#     collection_name=\"local_demo\",\n",
    "#     embedding_model=MODEL_NAME\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Di1P7HYbsHzu"
   },
   "source": [
    "#### Sentence Chunking & Handshake Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fM-Ucivslb1u",
    "outputId": "a07ac3af-c64c-4a37-f099-d73cad44d464"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 2 semantic chunks and stored them in Qdrant!\n"
     ]
    }
   ],
   "source": [
    "from chonkie import QdrantHandshake, SentenceChunker\n",
    "chunker = SentenceChunker(\n",
    "    tokenizer='bert-base-uncased',\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=10\n",
    ")\n",
    "\n",
    "chunks = chunker.chunk(sample_text)\n",
    "\n",
    "# Handshake! (Embed and Insert in one line)\n",
    "cloud_handshake.write(chunks)\n",
    "\n",
    "print(f\"Created {len(chunks)} semantic chunks and stored them in Qdrant!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s0X9WEyjlby2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRKDfNFHQ7uY"
   },
   "source": [
    "#### Notes\n",
    "- Vector Size: Ensure the length of the list in `vector=[...]` exactly matches the size defined in VectorParams (we have, 4).\n",
    "\n",
    "- Payloads: These are like JSON objects. you can store text, numbers, or booleans here to filter their search results later.\n",
    "\n",
    "- Batching: If they have thousands of points, you should insert them in batches (e.g., 100 at a time) rather than one by one for better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHypwiHdjN8G"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6EeHnLUjN5u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHkMi-fxjN22"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
